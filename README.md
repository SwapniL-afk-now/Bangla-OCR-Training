# Optimized Bangla OCR Training

A modular, multi-GPU optimized training pipeline for handwritten Bangla OCR using **Qwen-VL-2B**.

## ðŸš€ Key Features
- **Multi-GPU Scaling**: Seamlessly integrated with `accelerate`.
- **Memory Efficient**: 8-bit optimization and gradient checkpointing.
- **Dynamic Loss Weighting**: Automatically identifies and penalizes character-level confusion.
- **Robust Metrics**: Real-time CER/WER tracking during training.
- **GPU Augmentation**: High-speed image augmentations using `kornia`.

## ðŸ“ Project Structure
```text
.
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/          # Dataset, Collator, Augmentation
â”‚   â”œâ”€â”€ models/        # Model factory
â”‚   â”œâ”€â”€ utils/         # Metrics, Checkpoints, Confusion Matrix
â”‚   â”œâ”€â”€ config.py      # Training configuration
â”‚   â”œâ”€â”€ losses.py      # Focal and Confusion losses
â”‚   â””â”€â”€ trainer.py     # Core training logic
â”œâ”€â”€ train.py           # Main entry point
â”œâ”€â”€ requirements.txt   # Dependencies
â””â”€â”€ README.md
```

## ðŸ› ï¸ Setup

1. **Install Dependencies**:
```bash
pip install -r requirements.txt
```

2. **Configure Accelerate**:
```bash
accelerate config
```

## ðŸ“ˆ Training

### Standard (Interactive)
To start training with multi-GPU support:
```bash
accelerate launch train.py
```

### Kaggle / Notebooks (Non-interactive)
On Kaggle with **Dual T4 GPUs**, use the following command to ensure all internal configurations (like mixed precision and accumulation steps) are respected:

```bash
!accelerate launch --multi_gpu --num_processes=2 --mixed_precision=fp16 train.py
```

> [!NOTE]
> The script automatically reads `gradient_accumulation_steps` and `mixed_precision` from `src/config.py`. The launch flags ensure the environment is correctly initialized for two GPUs.

Settings can be adjusted in `src/config.py`.

## ðŸ§  Model
The pipeline uses **Qwen/Qwen3-VL-2B-Instruct** as the base model with **LoRA** fine-tuning.

## ðŸ“Š Loss Function
A combination of **Focal Loss** and **Confusion-Weighted Cross Entropy**:
- **Focal Loss**: Focuses on hard examples.
- **Confusion Weighting**: Dynamically increases loss for characters the model frequently misidentifies.

## ðŸ“œ License
MIT
