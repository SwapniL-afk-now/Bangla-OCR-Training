# Optimized Bangla OCR Training

A modular, multi-GPU optimized training pipeline for handwritten Bangla OCR using **Qwen-VL-2B**.

## ğŸš€ Key Features
- **Multi-GPU Scaling**: Seamlessly integrated with `accelerate`.
- **Memory Efficient**: 8-bit optimization and gradient checkpointing.
- **Dynamic Loss Weighting**: Automatically identifies and penalizes character-level confusion.
- **Robust Metrics**: Real-time CER/WER tracking during training.
- **GPU Augmentation**: High-speed image augmentations using `kornia`.

## ğŸ“ Project Structure
```text
.
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/          # Dataset, Collator, Augmentation
â”‚   â”œâ”€â”€ models/        # Model factory
â”‚   â”œâ”€â”€ utils/         # Metrics, Checkpoints, Confusion Matrix
â”‚   â”œâ”€â”€ config.py      # Training configuration
â”‚   â”œâ”€â”€ losses.py      # Focal and Confusion losses
â”‚   â””â”€â”€ trainer.py     # Core training logic
â”œâ”€â”€ train.py           # Main entry point
â”œâ”€â”€ requirements.txt   # Dependencies
â””â”€â”€ README.md
```

## ğŸ› ï¸ Setup

1. **Install Dependencies**:
```bash
pip install -r requirements.txt
```

2. **Configure Accelerate**:
```bash
accelerate config
```

## ğŸ“ˆ Training

To start training with multi-GPU support:
```bash
accelerate launch train.py
```

Settings can be adjusted in `src/config.py`.

## ğŸ§  Model
The pipeline uses **Qwen/Qwen3-VL-2B-Instruct** as the base model with **LoRA** fine-tuning.

## ğŸ“Š Loss Function
A combination of **Focal Loss** and **Confusion-Weighted Cross Entropy**:
- **Focal Loss**: Focuses on hard examples.
- **Confusion Weighting**: Dynamically increases loss for characters the model frequently misidentifies.

## ğŸ“œ License
MIT
